# 弹性网络

弹性网络包括

- 限流

  限制流量，比如限制http/tcp连接数、多余的连接数直接返回503，避免太高的并发对系统造成负担。

- 熔断

  流量/异常 等原因直接让线路断开一段时间，一个典型的现象就是使http全部连接都变成503了，等待一段时间后恢复。

  

  限流和熔断的区别：

  限流就好比电路里面的稳流器，能使电流稳定在多少以内。熔断就是可恢复保险丝，电流太大了直接断开，电流小了恢复。这2者经常会一起使用。

在istio 里面包含 连接池（ConnectionPool）限流和异常检测（outlierDetection）熔断。

## 初始化

#### 安装测试服务端

```text
kubectl apply -f samples/httpbin/httpbin.yaml
```

#### 安装测试试客户端

```
kubectl apply -f samples/httpbin/sample-client/fortio-deploy.yaml
```

## 限流

### 配置限流

```text
kubectl apply -f - <<EOF
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: httpbin
spec:
  host: httpbin
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 1
      http:
        http1MaxPendingRequests: 1
        maxRequestsPerConnection: 1
EOF
```

使用2个线程，测试20个http请求

```
kubectl exec -it $FORTIO_POD  -c fortio /usr/bin/fortio -- load -c 2 -qps 0 -n 20 -loglevel Warning http://httpbin:8000/get
08:19:17 I logger.go:97> Log level is now 3 Warning (was 2 Info)
Fortio 1.3.1 running at 0 queries per second, 4->4 procs, for 20 calls: http://httpbin:8000/get
Starting at max qps with 2 thread(s) [gomax 4] for exactly 20 calls (10 per thread + 0)
...
Sockets used: 6 (for perfect keepalive, would be 2)
Code 200 : 16 (80.0 %)
Code 503 : 4 (20.0 %)
All done 20 calls (plus 0 warmup) 5.190 ms avg, 343.8 qps
```

将线程增加到3个进行测试

```
kubectl exec -it $FORTIO_POD  -c fortio /usr/bin/fortio -- load -c 3 -qps 0 -n 20 -loglevel Warning http://httpbin:8000/get
08:24:25 I logger.go:97> Log level is now 3 Warning (was 2 Info)
Fortio 1.3.1 running at 0 queries per second, 4->4 procs, for 20 calls: http://httpbin:8000/get
Starting at max qps with 3 thread(s) [gomax 4] for exactly 20 calls (6 per thread + 2)
...
Sockets used: 13 (for perfect keepalive, would be 3)
Code 200 : 8 (40.0 %)
Code 503 : 12 (60.0 %)
```

可以发现503的结果变多了, 说明限流出现效果

### 限流配置

ConnectionPool可以对上游服务的并发连接数和请求数进行限制，适用于TCP和HTTP。ConnectionPool又称之是限流。

- tcp限流
  - maxConnections 最大连接数
  - connectTimeout 超时
  - tcpKeepalive 如果在套接字上设置SO_KEEPALIVE可以确保TCP 存活
    - Probes：在确定连接已死之前，在没有响应的情况下发送的keepalive探测的最大数量。默认值是使用系统级别的配置(除非写词参数覆盖，Linux默认值为9)。
    - Time：发送keep-alive探测前连接存在的空闲时间。默认值是使用系统的配置(除非写此参数，Linux默认值为7200s(即2小时)。
    - interval：探测活动之间的时间间隔。默认值是使用系统的配置(除非被覆盖，Linux默认值为75秒)。
- http限流
  - http1MaxPendingRequests http请求pending状态的最大请求数，从应用容器发来的HTTP请求的最大等待转发数，默认是1024
  - http2MaxRequests：后端请求的最大数量，默认是1024
  - maxRequestsPerConnection：在一定时间内限制对后端服务发起的最大请求数，如果超过了这个限制，就会开启限流。如果将这一参数设置为 1 则会禁止 keepalive 特性
  - idleTimeout：上游连接池连接的空闲超时
  - maxRetries：在给定时间内，集群中所有主机都可以执行的最大重试次数



## 熔断

### 配置熔断

下面这条规则, 每秒扫描一下上游主机，如果连续失败次数大于1次，那么就会驱逐100%的流量，然后30秒后恢复. 

```
kubectl apply -f - <<EOF
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: httpbin
spec:
  host: httpbin
  trafficPolicy:
    outlierDetection:
      baseEjectionTime: 30s
      consecutiveErrors: 1
      interval: 1s
      maxEjectionPercent: 100
EOF
```



#### 异常(熔断)配置

outlierDetection针对异常情况进行配置

- consecutiveErrors 失败的次数。对于HTTP服务，502、503、504会被认为异常，TPC服务，连接超时即异常
- Interval 驱逐的时间间隔，默认是10秒
- baseEjectionTime 最小驱逐时间。驱逐时间会随着错误次数增加而增加。即错误次数*最小驱逐时间
- maxEjectionPercent 负载均衡池中可以被驱逐的实例的最大比例。以免某个接口瞬时不可用，导致太多实例被驱逐，进而导致服务整体全部不可用。
- minHealthPercent 有最小健康百分比的阈值

该配置表示每秒钟扫描一次上游主机，连续失败1 次返回 5xx 错误码的所有主机会被移出连接池 3 分钟
